{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad61b266-703b-48f5-abf1-cf6a4b315ff1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Large Language Models for Education\n",
    "\n",
    "In this notebook, we demonstrate how to use large language models (LLMs) for use cases in education.  LLMs can be used for tasks such as summarization, question-answering, or the generation of question & answer pairs.\n",
    "\n",
    "The first part of this notebook sets up a SageMaker endpoint, using a **FLAN T5** model, on a single `p3.2xlarge` instance.  Next we show how the endpoint can be queried, and some subroutines are added to demonstrate prompts for summarization, question-answering and the generation of question & answer pairs.\n",
    "\n",
    "The final section is split into four demos on querying a university-level text on quantum computing, an example syllabus, a guide on \"design thinking\", and an ebook text from [Project Gutenberg](https://www.gutenberg.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68643ba4-a1cb-4459-889b-2200a9b2a00d",
   "metadata": {},
   "source": [
    "https://github.com/ngnatk/amazon-sagemaker-immersion-day-for-research/tree/main/10.%20Generative_AI/2.%20Education_QnA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bdb91-fa4a-43d1-90e4-52a319b57743",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.Setting up the SageMaker Endpoint using SageMaker Jumpstart\n",
    "\n",
    "### 1.1 Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62662a0-fa82-475c-b671-2ebeb67467ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199a7594-b678-49f8-bc7c-068377a514cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U langchain --quiet\n",
    "!pip install -U PyPDF2 --quiet\n",
    "!pip install ipywidgets==7.0.0 --quiet\n",
    "!pip install --upgrade sagemaker --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ccd1ea-7ec2-44f7-8540-a9899873b0a4",
   "metadata": {},
   "source": [
    "### 1.2 Deploying a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011c244c-ca72-40f2-b7c9-7a94f25becf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import image_uris, instance_types, model_uris, script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.utils import name_from_base\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae27a1cd-6507-4a12-acfa-a4d2cf6289e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the folder where the model weights will be stored\n",
    "!mkdir -p download_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747d0e08-797c-4e34-8db0-274d9ab58d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sagemaker_session(local_download_dir) -> sagemaker.Session:\n",
    "    \"\"\"Return the SageMaker session.\"\"\"\n",
    "\n",
    "    sagemaker_client = boto3.client(\n",
    "        service_name=\"sagemaker\", region_name=boto3.Session().region_name\n",
    "    )\n",
    "\n",
    "    session_settings = sagemaker.session_settings.SessionSettings(\n",
    "        local_download_dir=local_download_dir\n",
    "    )\n",
    "\n",
    "    # the unit test will ensure you do not commit this change\n",
    "    session = sagemaker.session.Session(\n",
    "        sagemaker_client=sagemaker_client, settings=session_settings\n",
    "    )\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a5e29d-29af-4258-b107-a9d5a545e0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "model_id, model_version = \"huggingface-text2text-flan-t5-xl\", \"*\"\n",
    "_model_env_variable_map = {\n",
    "    \"huggingface-text2text-flan-t5-xl\": {\"MMS_DEFAULT_WORKERS_PER_MODEL\": \"1\"},\n",
    "}\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{model_id}\")\n",
    "instance_type = 'ml.p3.2xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102add5b-e0f7-431f-8c36-bcb7d11a39b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the inference docker container uri. This is the base HuggingFace container image for the default model above.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the inference script uri. This includes all dependencies and scripts for model loading, inference handling etc.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# Retrieve the model uri.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# Create the SageMaker model instance\n",
    "if model_id in _model_env_variable_map:\n",
    "    # For those large models, we already repack the inference script and model\n",
    "    # artifacts for you, so the `source_dir` argument to Model is not required.\n",
    "    model = Model(\n",
    "        image_uri=deploy_image_uri,\n",
    "        model_data=model_uri,\n",
    "        role=aws_role,\n",
    "        predictor_cls=Predictor,\n",
    "        name=endpoint_name,\n",
    "        env=_model_env_variable_map[model_id],\n",
    "    )\n",
    "else:\n",
    "    model = Model(\n",
    "        image_uri=deploy_image_uri,\n",
    "        source_dir=deploy_source_uri,\n",
    "        model_data=model_uri,\n",
    "        entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "        role=aws_role,\n",
    "        predictor_cls=Predictor,\n",
    "        name=endpoint_name,\n",
    "        sagemaker_session=get_sagemaker_session(\"download_dir\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26efc2da-eeab-406e-8a8a-b730e1c75e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying endpoint jumpstart-example-huggingface-text2text-2023-06-05-03-18-35-650 on 1 x ml.p3.2xlarge (this will take approximately 6-8 minutes)\n",
      "-----------!CPU times: user 290 ms, sys: 13.1 ms, total: 303 ms\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "print(f'Deploying endpoint {endpoint_name} on 1 x {instance_type} (this will take approximately 6-8 minutes)')\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47f6006-3b1a-48cb-847f-0891d084c30d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deployed endpoint jumpstart-example-huggingface-text2text-2023-06-05-03-18-35-650 on 1 x ml.p3.2xlarge\n"
     ]
    }
   ],
   "source": [
    "print(f'Successfully deployed endpoint {endpoint_name} on 1 x {instance_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe61f6c-8640-43db-a1a6-93f527f54321",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Subroutines for text extraction and for querying the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9cc0ae-a2cb-49a3-bda9-fe2a87f7ae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('max_colwidth', 80)  # Set max column width for displaying Pandas Dataframes\n",
    "QNA_OUTPUT_STYLE = 'HTML'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb550d18-8e8e-463d-8afd-ec99383936d8",
   "metadata": {},
   "source": [
    "### 2.1 Extract Pages from PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4722ee-f380-4dd1-8afc-ea9d696aee34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_pages(pdf_file, max_pages=25):\n",
    "    pages = []\n",
    "    with open(pdf_file, 'rb') as f:\n",
    "        for i, page in enumerate(PyPDF2.PdfReader(f).pages):\n",
    "            if i == max_pages:\n",
    "                break\n",
    "            pages.append(page.extract_text())\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dd287-ab0e-4883-b180-5464b4ea41ab",
   "metadata": {},
   "source": [
    "### 2.2 Download a text-based ebook from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b99ead0d-a80c-430d-991e-8724177fc88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_book(url):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        return r.content.decode('utf-8')\n",
    "    else:\n",
    "        print(f'Failed to download {url}. Status code = {r.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4886ff-061b-4c26-937a-a612b4b6db12",
   "metadata": {},
   "source": [
    "### 2.3 Extract paragraphs from a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f280092-35bc-4f6b-9fc0-3a01bb4c58f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_website_text(url):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        return r.text\n",
    "    else:\n",
    "        print(f'Failed to access {url}. Status code = {r.status_code}')\n",
    "        return None\n",
    "    \n",
    "def extract_paragraphs_from_html(text):\n",
    "    html = BeautifulSoup(text, 'html.parser')\n",
    "    return [ p.text for p in html.body.select('p') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3f8d3-3ff4-4b1d-a51b-124bef928df2",
   "metadata": {},
   "source": [
    "### 2.4 Generate texts, or query an endpoint with prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "348db1eb-e8ff-4041-b75f-196c0e88384e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newline, bold, unbold = '\\n', '\\033[1m', '\\033[0m'\n",
    "lightred, lightgreen, lightyellow, lightblue = '\\033[91m', '\\033[92m', '\\033[93m', '\\033[94m'\n",
    "lightmagenta, lightcyan, reset = '\\033[95m', '\\033[96m', '\\33[39m'\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json):\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    return response\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    model_predictions = json.loads(query_response['Body'].read())\n",
    "    generated_text = model_predictions['generated_texts']\n",
    "    return generated_text\n",
    "\n",
    "def generate_text_from_prompt(prompt, max_length=300, max_time=50, temperature=0.5,\n",
    "                              top_k=None, top_p=None, do_sample=True, seed=None):\n",
    "    payload = {\n",
    "        \"text_inputs\": prompt,\n",
    "        \"max_length\": max_length,\n",
    "        \"max_time\": max_time,\n",
    "        \"temperature\": temperature,\n",
    "        \"do_sample\": do_sample\n",
    "    }\n",
    "    if top_k is not None:\n",
    "        payload['top_k'] = top_k\n",
    "    if top_p is not None:\n",
    "        payload['top_p'] = top_p\n",
    "    if seed is not None:\n",
    "        payload['seed'] = seed\n",
    "\n",
    "    query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "    return parse_response_multiple_texts(query_response)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6ef33-3f77-4886-a0f0-c7a803d4872d",
   "metadata": {},
   "source": [
    "To further customize the outputs of the large language model, the following parameters are available:\n",
    "\n",
    "* **max_length:** Model generates text until the output length (which includes the input context length) reaches `max_length`. If specified, it must be a positive integer.\n",
    "* **max_time:** The maximum amount of time you allow the computation to run for in seconds. Generation will still finish the current pass after allocated time has been passed. This setting can help to generate a response prior to endpoint invocation response time out errors.\n",
    "* **num_return_sequences:** Number of output sequences returned. If specified, it must be a positive integer.\n",
    "* **num_beams:** Number of beams used in the greedy search. If specified, it must be integer greater than or equal to `num_return_sequences`.\n",
    "* **no_repeat_ngram_size:** Model ensures that a sequence of words of `no_repeat_ngram_size` is not repeated in the output sequence. If specified, it must be a positive integer greater than 1.\n",
    "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "* **early_stopping:** If True, text generation is finished when all beam hypotheses reach the end of sentence token. If specified, it must be boolean.\n",
    "* **do_sample:** If True, sample the next word as per the likelihood. If specified, it must be boolean.\n",
    "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
    "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
    "* **seed:** Fix the randomized state for reproducibility. If specified, it must be an integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147e4af6-6cbd-4b57-ac28-6cbd715cb3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(text, seed=None):\n",
    "    return generate_text_from_prompt(\n",
    "        f\"\"\"Summarize the following text in 100 words:\\n\\n{text}\\n\\nSummary:\"\"\",\n",
    "        temperature=0.2,  # Low temperature for summarization\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def ask(text, question, seed=None):\n",
    "    return generate_text_from_prompt(\n",
    "        f\"\"\"My text is:\\n{text}\\n\\n{question}\"\"\",\n",
    "        temperature=0.01,  # Lowest temperature for accuracy\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def extract_question(text, seed=None):\n",
    "    return generate_text_from_prompt(\n",
    "        f\"\"\"EXTRACT QUESTIONS\\nContext:\\n{text}\\nQuestion:\"\"\",\n",
    "        temperature=1.0,  # Maximum temperature for creativity\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def create_qna_pairs(text, n, output_style='HTML', qn_seed=None, ans_seed=None):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for i in range(n):\n",
    "        questions.append(extract_question(text, qn_seed))\n",
    "        answers.append(ask(text, questions[i], ans_seed))\n",
    "        if output_style == 'HTML':\n",
    "            output = \\\n",
    "            f\"\"\"<b>{i+1}</b>. <b><font color=#FF7F50>Question</font></b>: {questions[i]}\n",
    "            <b><font color=#FA8072>Answer</font></b>: {answers[i]}\"\"\"\n",
    "            display(HTML(output))\n",
    "        elif output_style == 'text':\n",
    "            print(f\"\"\"{i+1}. {lightblue}{bold}Question{unbold}{reset}: {questions[i]} {lightcyan}{bold}Answer{unbold}{reset}: {answers[i]}\"\"\")\n",
    "    if output_style == 'table':\n",
    "        return pd.DataFrame({\n",
    "            'Question': questions,\n",
    "            'Answer': answers\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55310f-fab2-40d8-aa5a-0e2b2588adb0",
   "metadata": {},
   "source": [
    "## 3. LLM Demos for Education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad5a23-488d-4b9f-8d2e-7a07130a9a2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this notebook, we use the following texts to demonstrate summarization tasks and the generation of question & answer pairs.\n",
    "\n",
    "1. Quantum Computing from Wikipedia: https://en.wikipedia.org/wiki/Quantum_computing\n",
    "<!-- 1. Quantum Computing and Quantum Information (by Nielsen & Chuang): https://michaelnielsen.org/qcqi/QINFO-book-nielsen-and-chuang-toc-and-chapter1-nov00.pdf (this is a sample chapter from [this website](https://michaelnielsen.org/qcqi/)) -->\n",
    "2. Primary School Science Syllabus (by Ministry of Education, Singapore): https://www.moe.gov.sg/-/media/files/primary/syllabus/2023-primary-science.ashx\n",
    "3. Design Thinking (by Michael Shanks, Stanford): https://web.stanford.edu/~mshanks/MichaelShanks/files/509554.pdf \n",
    "4. Winnie the Pooh (by Alan Alexander Milne): https://www.gutenberg.org/ebooks/67098.txt.utf-8\n",
    "5. Attention is all you need (by Vaswani et al): https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "Note that for this notebook, we are using the Flan T5 XL model for simplicity and ease of deployment--additional fine tuning or using improved models would be required to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94d29ef7-870c-456a-8a58-b60c788de24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download pdfs and texts with the `curl` command. Flags used here are `-L` (allow redirects),\n",
    "# `-s` (for silent mode) and `-o` (to specify the output file name).\n",
    "\n",
    "# Quantum Computation and Quantum Information (by Nielsen & Chuang) (sample chapter)\n",
    "# !curl -Ls https://michaelnielsen.org/qcqi/QINFO-book-nielsen-and-chuang-toc-and-chapter1-nov00.pdf -o nielsen-n-chuang-ch01.pdf\n",
    "\n",
    "# Primary School Science Syllabus (by Ministry of Education, Singapore)\n",
    "!curl -Ls https://www.moe.gov.sg/-/media/files/primary/syllabus/2023-primary-science.ashx -o 2023-primary-science.pdf\n",
    "\n",
    "# Design Thinking (by Michael Shanks, Stanford)\n",
    "!curl -Ls https://web.stanford.edu/~mshanks/MichaelShanks/files/509554.pdf -o design-thinking.pdf\n",
    "\n",
    "# Winnie the Pooh (by Alan Alexander Milne)\n",
    "!curl -LOs https://www.gutenberg.org/ebooks/67098.txt.utf-8\n",
    "\n",
    "# Attention is all you need (by Vaswani et al)\n",
    "!curl -Ls https://arxiv.org/pdf/1706.03762.pdf -o attention.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee88e7-9ad6-4e04-add3-7d3842ed3c3c",
   "metadata": {},
   "source": [
    "### 3.1 Wikipedia Page on Quantum Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72ea7b6f-6174-48ba-aa28-33ca600dcee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NCHARS = 400     # We will show just the first and last 400 characters of each extracted text. Increase this number for more context.\n",
    "NQUESTIONS = 12  # The number of Q&A pairs that we will generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f5f17c-bb54-4bdd-bf2c-2c63b4d9ae9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantum computer is a computer that exploits quantum mechanical phenomena.\n",
      "At small scales, physical matter exhibits properties of both particles and waves, and quantum computing leverages this behavior using specialized hardware.\n",
      "Classical physics cannot explain the operation of these quantum devices, and a scalable quantum computer could perform some calculations exponentially faster than any ...\n",
      "\n",
      "...s,[19] which drew significant attention to the field of quantum computing.[20]\n",
      "In 1996, Grover's algorithm established a quantum speedup for the widely applicable unstructured search problem.[21][22] The same year, Seth Lloyd proved that quantum computers could simulate quantum systems without the exponential overhead present in classical simulations,[23] validating Feynman's 1982 conjecture.[24]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt1_paragraphs = extract_paragraphs_from_html(\n",
    "    get_website_text('https://en.wikipedia.org/wiki/Quantum_computing')\n",
    ")\n",
    "txt1 = '\\n\\n'.join(txt1_paragraphs[1:8])\n",
    "print(f'{txt1[:NCHARS]}...\\n\\n...{txt1[-NCHARS:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a891c-e574-4ea3-ac7f-0d01e52aa38e",
   "metadata": {},
   "source": [
    "#### Key word Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114fd4e1-c7c7-4ab4-9a85-4f057bafb4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum computing, qubit, superposition, quantum theory\n"
     ]
    }
   ],
   "source": [
    "KEY_WORDS = generate_text_from_prompt(\n",
    "    f'FIND KEY WORDS\\n\\nContext:\\n{txt1}\\nKey Words:',\n",
    "    seed=123\n",
    ")\n",
    "key_word_list = KEY_WORDS.split(', ')\n",
    "print(KEY_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67d45e19-f1c1-4a17-82c1-e815c39faf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as above, but using Amazon Comprehend. Requires `ComprehendReaadOnly` permissions.\n",
    "\n",
    "# txt_list = txt1_paragraphs[2:20]  # Max is 25 paragraphs\n",
    "# try:\n",
    "#     client = boto3.client('comprehend')\n",
    "#     key_phrases = client.batch_detect_key_phrases(\n",
    "#         TextList=txt_list,\n",
    "#         LanguageCode='en'\n",
    "#     )\n",
    "# except client.exceptions.BatchSizeLimitExceededException as e:\n",
    "#     print(f'{e}')\n",
    "#     print(f'Your batch size is: {len(txt_list)}')\n",
    "# except client.exceptions.TextSizeLimitExceededException as e:\n",
    "#     print(f'{e}')\n",
    "#     print(f'Your maximum input text size is: {max([ len(x) for x in txt_list ])}')\n",
    "# except Exception as e:\n",
    "#     print(f'Error {e}')\n",
    "#     print('If this is an AccessDeniedException, you need to add `ComprehendReaadOnly` permissions to {aws_role}')\n",
    "# else:    \n",
    "#     phrases = set()\n",
    "#     for x in key_phrases['ResultList']:\n",
    "#         for p in x['KeyPhrases']:\n",
    "#             if p['Score'] > 0.999:\n",
    "#                 phrases.add(p['Text'])\n",
    "#     print(','.join(phrases))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9859bd8-e743-4a34-817f-06405a06a2d4",
   "metadata": {},
   "source": [
    "#### Summary of key points\n",
    "\n",
    "For each of each of paragraphs 3-11, let's create a short summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe371a26-340a-41d3-9138-36479871dce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "for i, x in enumerate(txt1_paragraphs[2:12]):\n",
    "    summary.append(f'{i+1}. {summarize(x[:1500])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "024e309d-0ac4-4b40-b168-04ebea1411b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Key Points</h4><li>1. Quantum computing is a branch of computer science that uses quantum mechanics to perform calculations.</li>\n",
       "<li>2. Quantum computing is the computational process of constructing and manipulating quantum bits (qubits) in a quantum computer.</li>\n",
       "<li>3. Quantum computing is the study of the computational complexity of problems with respect to quantum computers.</li>\n",
       "<li>4. The emergence of quantum computing in the 1970s and 1980s ushered in a new era of collaboration between quantum physics and computer science.</li>\n",
       "<li>5. The field of quantum computing has been a hot topic since the 1970s.</li>\n",
       "<li>6. The field of quantum computing has developed rapidly since the 1980s.</li>\n",
       "<li>7. Quantum computing is the development of a computer that uses quantum physics to perform computations that are impossible for a classical computer.</li>\n",
       "<li>8. The quantum computer is a computer that uses quantum physics to perform computations.</li>\n",
       "<li>9. Quantum computing is a growing field of research.</li>\n",
       "<li>10. Quantum computing is a hot topic, and it's not just for the techies.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\n",
    "    '<h4>Key Points</h4>' + \n",
    "    '\\n'.join([ f'<li>{x}</li>' for x in summary ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84410c39-d71c-44f4-95d2-744cf527a9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum computing is the development of a computer that uses quantum physics to perform computations that are impossible for a classical computer.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to summarize the 10 points above\n",
    "summarize('\\n'.join(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa90c0b-31e4-4286-9995-48ca4f66efad",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Checking for correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b40942c-d2fc-4121-8143-a5875d5d4f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantum computer is a computer that exploits quantum mechanical phenomena\n"
     ]
    }
   ],
   "source": [
    "prompt=f\"\"\"Context:{txt1}\n",
    "What is quantum computing?\"\"\"\n",
    "answer = generate_text_from_prompt(prompt, temperature=0.01)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c12861c0-991c-4690-8a2c-a6d655ab3742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "prompt=f\"\"\"Context:{txt1}\n",
    "Question: What is quantum computing?\n",
    "Answer: {answer}\n",
    "Student: Quantum computing is using computers with quantum dots\n",
    "Is this answer correct?\"\"\"\n",
    "print(generate_text_from_prompt(prompt, temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d663433-8b29-4dfe-8e11-542c48ab919e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "prompt=f\"\"\"Context:{txt1}\n",
    "Question: What is quantum computing?\n",
    "Answer: {answer}\n",
    "Student: Quantum computing involves using computers that make use of quantum mechanics\n",
    "Is this answer correct?\"\"\"\n",
    "print(generate_text_from_prompt(prompt, temperature=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab797e5-539b-49e4-8d8b-01113d7b7a04",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generation of Question & Answer Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cd4876c-b5cb-498d-ac7f-0b0b52c415a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: How many years ago did Paul Benioff introduce a quantum Turing machine?\n",
       "            <b><font color=#FA8072>Answer</font></b>: 30"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What year was the first modern \"Quantum Computer\" invented?\n",
       "            <b><font color=#FA8072>Answer</font></b>: "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: What are the similarities between a Qubit and a Bit?\n",
       "            <b><font color=#FA8072>Answer</font></b>: a qubit can exist in a superposition of its two \"basis\" states, which loosely means that it is in both states simultaneously"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: What year did Grover's algorithm was introduced?\n",
       "            <b><font color=#FA8072>Answer</font></b>: 1996"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: How long before Paul Benioff came up with quantum turing machine did the Church–Turing thesis come into effect?\n",
       "            <b><font color=#FA8072>Answer</font></b>: "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: How long since the quantum Turing machine was introduced was quantum computing considered to be a practical field?\n",
       "            <b><font color=#FA8072>Answer</font></b>: 30"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: How long after Paul Benioff introduced the quantum Turing machine did Grover's algorithm establish a quantum speedup for the widely applicable unstructured search problem?\n",
       "            <b><font color=#FA8072>Answer</font></b>: 22"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: What is the name of the basic unit of information in quantum computing?\n",
       "            <b><font color=#FA8072>Answer</font></b>: qubit"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: Why did physicists switch from a mathematical model to a model in computer science?\n",
       "            <b><font color=#FA8072>Answer</font></b>: When digital computers became faster, physicists faced an exponential increase in overhead when simulating quantum dynamics"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: What are two concepts that quantum computers obey the Church-Turing thesis?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Any computational problem that can be solved by a classical computer can also be solved by a quantum computer"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>11</b>. <b><font color=#FF7F50>Question</font></b>: In what year did the Church-Turing thesis come into being?\n",
       "            <b><font color=#FA8072>Answer</font></b>: unanswerable"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>12</b>. <b><font color=#FF7F50>Question</font></b>: What might be considered the first demonstration of quantum computation?\n",
       "            <b><font color=#FA8072>Answer</font></b>: quantum Turing machine"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(txt1, NQUESTIONS, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0fe4f5-8388-4644-8ba9-7c112fece16e",
   "metadata": {},
   "source": [
    "### 3.2 Primary School Science Syllabus (by Ministry of Education, Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d12f022-8a27-456e-b296-5f92f5bd1adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "primary_science = extract_pages('2023-primary-science.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a67ce5a7-6fd6-42b0-aa6e-adab18406937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "15 \n",
      "OFFICIAL (OPEN)  \n",
      " \n",
      " Interactions  \n",
      " \n",
      "Interactions are the actions between and within living and non -living systems in the \n",
      "environment. Understanding these interactions helps us see relationships between the \n",
      "factors/variables in the environment. We can also appreciate the consequ ences of our \n",
      "actions and play our part in conservation. The essential takeaways and key inquiry \n",
      "questions fo...\n",
      "\n",
      "\n",
      "...s, living \n",
      "and non -living things in the \n",
      "environment.   \n",
      "• Interactions within the environment can \n",
      "have positive or negative impacts.  \n",
      "• Conservation is important to ensure \n",
      "continuity of life and availability of \n",
      "resources.  \n",
      " • What are the types of \n",
      "interactions around us?  \n",
      "• How do interactions affect the \n",
      "environment and us?  \n",
      "• Why is it important for us to \n",
      "conserve the environment?  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "txt2 = primary_science[15]  # Extract page 16\n",
    "print(f'{txt2[:NCHARS]}...\\n\\n\\n...{txt2[-NCHARS:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5d25bb5-07b5-4c43-931c-d7fc408954ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: What are the three main themes in this week's quiz?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Interactions Energy"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: How do atoms change shape?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Essential Takeaways Key Inquiry Questions • What are the types of interactions around us? • How do interactions affect the environment and us? • How do atoms change shape?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: How do energy and interactions function with each other?\n",
       "            <b><font color=#FA8072>Answer</font></b>: What are the different forms of energy around us?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: Which two activities are part of the Unit 1 science theme of Theme A ?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Interactions and Energy"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: What are the different forms of energy around us?\n",
       "            <b><font color=#FA8072>Answer</font></b>: What are the different forms of energy around us?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: How does understanding interactions and energy relate to the overall theme?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Understanding interactions and energy helps us see relationships between the factors/variables in the environment."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: How is energy used in everyday life?\n",
       "            <b><font color=#FA8072>Answer</font></b>: What are the different forms of energy around us?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: What type of energy is around us?\n",
       "            <b><font color=#FA8072>Answer</font></b>: What are the different forms of energy around us?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: Which of the following are the characteristics of interactions involving living and nonliving systems, and why can it be beneficial?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Understanding interactions helps us see relationships between the factors/variables in the environment."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: What do non-living things do?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Essential Takeaways Key Inquiry Questions • What are the different forms of energy around us? • How is energy used in everyday life? • Why is it important to conserve energy? • What are the types of interactions around us? • How do interactions affect the environment and us? • Why is it important for us to conserve the environment?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>11</b>. <b><font color=#FF7F50>Question</font></b>: What can we do in order to understand interactions around us?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Essential Takeaways Key Inquiry Questions • Energy is required for things to work. • There are various forms of energy and they can be converted from one form to another. • Some sources of energy can be depleted and we play an important role in energy conservation. • What are the different forms of energy around us? • How is energy used in everyday life? • Why is it important to conserve energy? • What are the types of interactions around us? • How do interactions affect the environment and us? • Why is it important for us to conserve the environment? What can we do in order to understand interactions around us?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>12</b>. <b><font color=#FF7F50>Question</font></b>: Which of the following is one of the requirements for living in the world?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Energy"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(txt2, NQUESTIONS, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e07611-6abe-4463-8654-30297985a0c1",
   "metadata": {},
   "source": [
    "### 3.3 Design Thinking (by Michael Shanks, Stanford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68d0ccca-4761-43a3-ac27-2dfa98f01981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "design_thinking = extract_pages('design-thinking.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bbd8575-93ba-4ca3-b560-d60f4bda5be0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAT is the Empathize mode\n",
      "Empathy is the centerpiece of a human-centered design process.  The Empathize mode is \n",
      "the work you do to understand people, within the context of your design challenge.  It is your \n",
      "eﬀort to understand the way they do things and why, their physical and emotional needs, how \n",
      "they think about world, and what is meaningful to them. \n",
      "WHY empathize\n",
      "As a design thinker, the p...\n",
      "\n",
      "\n",
      "...t ideas that your team \n",
      "generated during brainstorming.  Carry the two or three ideas that receive the most \n",
      "votes forward into prototyping.  In this way, you preserve innovation potential by \n",
      "carrying multiple ideas forward—a radically diﬀerent approach than settling on the \n",
      "single idea that at least the majority of the team can agree upon.\n",
      "Maximize your innovation potentialIdeate\n",
      "PrototypeIdeate\n"
     ]
    }
   ],
   "source": [
    "txt3 = '\\n\\n'.join(design_thinking[1:4])\n",
    "print(f'{txt3[:NCHARS]}...\\n\\n\\n...{txt3[-NCHARS:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ea7ace8-bdcd-46e2-9791-1b28074bcda7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: What is the primary tool of Empathize?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Observe. View users and their behavior in the context of their lives. As much as possible do observations in relevant contexts in addition to interviews."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What the \"right\" challenge in a design process?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Define"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: What is the Define mode and what does it involve?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Define mode of the design process is all about bringing clarity and focus to the design space."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: Which two modes of interaction should a designer combine?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Observe and Engage"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: From what is the greatest value that the synthesis of the research you perform give?\n",
       "            <b><font color=#FA8072>Answer</font></b>: INSIGHT"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: What is the most important step of the design process?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Empathize"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: Why is empathizing important?\n",
       "            <b><font color=#FA8072>Answer</font></b>: As a design thinker, the problems you are trying to solve are rarely your own—they are those of a particular group of people; in order to design for them, you must gain empathy for who they are and what is important to them."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: Which of the following is true of a designer's point of view - explicit, concise or unresolved?\n",
       "            <b><font color=#FA8072>Answer</font></b>: explicit"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: What happens in the Define mode?\n",
       "            <b><font color=#FA8072>Answer</font></b>: bringing clarity and focus to the design space"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: What is required to gain empathy\n",
       "            <b><font color=#FA8072>Answer</font></b>: Observing what people do and how they interact with their environment gives you clues about what they think and feel. It also helps you learn about what they need. By watching people, you can capture physical manifestations of their experiences – what they do and say. This will allow you to infer the intangible meaning of those experiences in order to uncover insights. These insights give you direction to create innovative solutions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>11</b>. <b><font color=#FF7F50>Question</font></b>: Which mode is the most important?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Empathize"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>12</b>. <b><font color=#FF7F50>Question</font></b>: How do you become an instant expert on a subject?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Observe and engage with people."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(txt3, NQUESTIONS, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b220a-7c2d-4d23-abe8-8ff0323b0e3c",
   "metadata": {},
   "source": [
    "### 3.4 Winnie the Pooh (by Alan Alexander Milne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26672f79-120b-496f-897c-d4b603ee285e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "winnie_the_pooh = download_book('https://www.gutenberg.org/ebooks/67098.txt.utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f2bd54-248a-45b1-a882-2159f0a9e4df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER III\n",
      "\n",
      "                   IN WHICH POOH AND PIGLET GO HUNTING\n",
      "                        AND NEARLY CATCH A WOOZLE\n",
      "\n",
      "\n",
      "The Piglet lived in a very grand house in the middle of a beech-tree,\n",
      "and the beech-tree was in the middle of the forest, and the Piglet lived\n",
      "in the middle of the house. Next to his house was a piece of broken\n",
      "board which had: \"TRESPASSERS W\" on it. When Christopher Robin asked the\n",
      "Piglet what it meant, he said it was his grandfather's name, and had\n",
      "been in the family for a long time, Christopher Robin said you\n",
      "_couldn't_ be called Trespassers W, and Piglet said yes, you could,\n",
      "because his grandfather was, and it was short for Trespassers Will,\n",
      "which was short for Trespassers William. And his grandfather had had two\n",
      "names in case he lost one--Trespassers after an uncle, and William after\n",
      "Trespassers.\n",
      "\n",
      "\"I've got two names,\" said Christopher Robin carelessly.\n",
      "\n",
      "\"Well, there you are, that proves it,\" said Piglet.\n",
      "\n",
      "One fine winter's day when Piglet was brushing away the snow in front of\n",
      "his house, he happened to look up, and there was Winnie-the-Pooh. Pooh\n",
      "was walking round and round in a circle, thinking of something else, and\n",
      "when Piglet called to him, he just went on walking.\n",
      "\n",
      "\"Hallo!\" said Piglet, \"what are _you_ doing?\"\n",
      "\n",
      "\"Hunting,\" said Pooh.\n",
      "\n",
      "\"Hunting what?\"\n",
      "\n",
      "\"Tracking something,\" said Winnie-the-Pooh very mysteriously.\n",
      "\n",
      "\"Tracking what?\" said Piglet, coming closer.\n",
      "\n",
      "\"That's just what I ask myself. I ask myself, What?\"\n",
      "\n",
      "\"What do you think you'll answer?\"\n",
      "\n",
      "\"I shall have to wait until I catch up with it,\" said Winnie-the-Pooh.\n",
      "\"Now, look there.\" He pointed to the ground in front of him. \"What do\n",
      "you see there?\"\n",
      "\n",
      "\"Tracks,\" said Piglet. \"Paw-marks.\" He gave a little squeak of\n",
      "excitement. \"Oh, Pooh! Do you think it's a--a--a Woozle?\"\n",
      "\n",
      "\"It may be,\" said Pooh. \"Sometimes it is, and sometimes it isn't. You\n",
      "never can tell with paw-marks.\"\n",
      "\n",
      "With these few words he went on tracking, and Piglet, after watching him\n",
      "for a minute or two, ran after him. Winnie-the-Pooh had come to a sudden\n",
      "stop, and was bending over the tracks in a puzzled sort of way.\n",
      "\n",
      "\"What's the matter?\" asked Piglet.\n",
      "\n",
      "\"It's a very funny thing,\" said Bear, \"but there seem to be\n",
      "_two_ animals now. This--whatever-it-was--has been joined by\n",
      "another--whatever-it-is--and the two of them are now proceeding\n",
      "in company. Would you mind coming with me, Piglet, in case they\n",
      "turn out to be Hostile Animals?\"\n",
      "\n",
      "Piglet scratched his ear in a nice sort of way, and said that he had\n",
      "nothing to do until Friday, and would be delighted to come, in case it\n",
      "really _was_ a Woozle.\n",
      "\n",
      "\"You mean, in case it really is two Woozles,\" said Winnie-the-Pooh, and\n",
      "Piglet said that anyhow he had nothing to do until Friday. So off they\n",
      "went together.\n",
      "\n",
      "There was a small spinney of larch trees just here, and it seemed as if\n",
      "the two Woozles, if that is what they were, had been going round this\n",
      "spinney; so round this spinney went Pooh and Piglet after them; Piglet\n",
      "passing the time by telling Pooh what his Grandfather Trespassers W had\n",
      "done to Remove Stiffness after Tracking, and how his Grandfather\n",
      "Trespassers W had suffered in his later years from Shortness of Breath,\n",
      "and other matters of interest, and Pooh wondering what a Grandfather was\n",
      "like, and if perhaps this was Two Grandfathers they were after now, and,\n",
      "if so, whether he would be allowed to take one home and keep it, and\n",
      "what Christopher Robin would say. And still the tracks went on in front\n",
      "of them....\n",
      "\n",
      "Suddenly Winnie-the-Pooh stopped, and pointed excitedly in front of him.\n",
      "\"_Look!_\"\n",
      "\n",
      "\"_What?_\" said Piglet, with a jump. And then, to show that he hadn't\n",
      "been frightened, he jumped up and down once or twice more in an\n",
      "exercising sort of way.\n",
      "\n",
      "\"The tracks!\" said Pooh. \"_A third animal has joined the other two!_\"\n",
      "\n",
      "\"Pooh!\" cried Piglet. \"Do you think it is another Woozle?\"\n",
      "\n",
      "\"No,\" said Pooh, \"because it makes different marks. It is either Two\n",
      "Woozle\n"
     ]
    }
   ],
   "source": [
    "x = winnie_the_pooh.find('CHAPTER III')\n",
    "txt4 = winnie_the_pooh[x:x+4000]  # Extract the first 4000 characters of chapter 3\n",
    "print(txt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c62792e0-f044-4c34-aa19-b8126f5d0b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Piglet lived in a very grand house in the middle of a beech-tree, and the beech-tree was in the middle of the forest, and the Piglet lived in the middle of the house. Next to his house was a piece of broken board which had: \"TRESPASSERS W\" on it. When Christopher Robin asked the Piglet what it meant, he said it was his grandfather\\'s name, and had been in the family for a long time. Christopher Robin said you _could_ be called Trespassers W, and Piglet said yes, you could, because his grandfather was, and it was short for Trespassers Will, which was short for Trespassers William. And his grandfather had had two names in case he lost one--Trespassers after an uncle, and William after Trespassers.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt4, \"What is the storyline here?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55b3aad2-2775-41b8-b669-0df6a31d4c56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winnie-the-Pooh'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt4, \"Who is the main character?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24c67d89-c920-4b65-b220-37ba53341372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pooh and Piglet nearly catch a Woozle.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt4, \"What happens at the end?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2c908fd-9ba1-4bf7-9f36-c8767afd92ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: Where did Piglet live?\n",
       "            <b><font color=#FA8072>Answer</font></b>: in a very grand house in the middle of a beech-tree"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: Where was the animal that Pooh and Piglet tried to catch?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Woozle"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: Who thought that it may and may not be a Woozle?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Pooh"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: Where was the third animal when they first noticed them?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The third animal was not there when they first noticed them."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: What was on Pooh's piece of broken board?\n",
       "            <b><font color=#FA8072>Answer</font></b>: \"TRESPASSERS W\""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: What was the reason Piglet used to know his grandfather's second name?\n",
       "            <b><font color=#FA8072>Answer</font></b>: He had two names in case he lost one"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: How many names had Piglet received\n",
       "            <b><font color=#FA8072>Answer</font></b>: Two"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: Which name did Piglet's grandfather have?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Trespassers W"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: Where Piglet's Grandfather Trespassers W passed away?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Shortness of Breath"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: How does the article start?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Piglet lived in a very grand house in the middle of a beech-tree, and the beech-tree was in the middle of the forest, and the Piglet lived in the middle of the house."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>11</b>. <b><font color=#FF7F50>Question</font></b>: Who left the tree?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Piglet"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>12</b>. <b><font color=#FF7F50>Question</font></b>: What three things does Piglet tell Winnie the Pooh about his grandfather?\n",
       "            <b><font color=#FA8072>Answer</font></b>: He had done to Remove Stiffness after Tracking"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(txt4, NQUESTIONS, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64acef7-d4fe-49b7-9ca4-b1bb94fdc4c2",
   "metadata": {},
   "source": [
    "### 3.5 Attention is all you need (by Vaswani et al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b93e8343-42b5-4368-ad82-1b8cb90be303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention = extract_pages('attention.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e59b3356-fa39-4ba7-849d-f1c5aeb98886",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\n",
      "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
      "architectures [38, 24, 15].\n",
      "Recurrent models typically factor computation along the symbol positions of the input and output\n",
      "sequences. Aligning the positions to steps in computation time, they generate a se...\n",
      "\n",
      "\n",
      "...g. arXiv preprint arXiv:1601.06733 , 2016.\n",
      "[5]Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\n",
      "and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\n",
      "machine translation. CoRR , abs/1406.1078, 2014.\n",
      "[6]Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\n",
      "preprint arXiv:1610.02357 , 2016.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "txt5 = '\\n\\n'.join(attention[1:3] + attention[9:10])  # We will use pages 1, 2, and 9\n",
    "print(f'{txt5[:NCHARS]}...\\n\\n\\n...{txt5[-NCHARS:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b58dc-40b9-4a21-9057-bfc4cdef2c20",
   "metadata": {},
   "source": [
    "#### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edbf35b5-2c79-4924-a50b-49e6fef53c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt5, \"What is the main gist of the paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8674d667-7411-40ab-8b4c-90ce98ef1581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Transformer is the first transduction model relying entirely on attention to compute representations of its input and output without using sequence- aligned RNNs or convolution.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt5, \"What is the problem being solved?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e69d7c38-d788-41f1-a7f0-5abf463c0a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt5, \"What is the conclusion of the paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef8c05dc-a837-4454-b1aa-d13345dee2be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text will be split up into chunks of 1202 characters and summarized\n"
     ]
    }
   ],
   "source": [
    "chunk_size = len(txt5)//8\n",
    "print(f'The text will be split up into chunks of {chunk_size} characters and summarized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf3771d6-11de-416e-be0c-ac91b84d93f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Key Points</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1. The emergence of recurrent models in language modeling and transduction has been a major factor in the development of models for language modeling and transduction."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2. Attention mechanisms have been used in a variety of models for generative models, including attention-based models [1,2,19] and attention-based models [1,2,7,9,10] ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3. The Transformer is a neural sequence transduction model that uses self-attention to compute representations of its input and output."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4. odels have an encoder-decoder structure [5,2,35] . Here, the encoder maps an input sequence of symbol representations (x1;:::;x n)to a sequence of continuous representations z= (z1;:::;z n). Given z, the decoder then generates an output sequence (y1;:::;y m)of symbols one element at a time. At each step the model is auto-regressive [10,35], consuming the previously generated symbols as additional input when generating the next. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively. 3.1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [ 11] around each of the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is LayerNorm( x+ Sublayer( x))"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5. Model: The model is composed of a stack of N= 6 identical layers. The encoder is composed of two sub-layers, each with a different number of sub-layers. The decoder is composed of a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6. We present a model for English-to-German translation with a 4-layer RNN, which is trained on a small-data set."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7. Transformer is a sequence transduction model based entirely on attention."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8. We present a tensor-to-tensor translation model that learns a tensor representation of the input tensor and a tensor representation of the output tensor."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Key Points</h4>'))\n",
    "summary = []\n",
    "for i in range(8):\n",
    "    x0 = i*chunk_size\n",
    "    x1 = (i+1)*chunk_size\n",
    "    line_summary = f'{i+1}. {summarize(txt5[x0:x1])}'\n",
    "    display(HTML(line_summary))\n",
    "    summary.append(line_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b10a987c-c5f6-4d99-a587-1aadf5b37878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: How does the Transformer differ from previous models based on attention mechanisms?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What architecture can be used for sequence transduction?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Transformer - model architecture"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: How does the Transformer architecture differ from existing models?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Transformer architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: 2.1 Model Architecture.2.1 Attention mechanisms The Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
       "            <b><font color=#FA8072>Answer</font></b>: 2.1 Model Architecture.2.1 Attention mechanisms The Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: Who are the referees for this paper?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Nal Kalchbrenner Stephan Gouws"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: Where can we get the code used to train and evaluate our models ?\n",
       "            <b><font color=#FA8072>Answer</font></b>: https://github.com/ tensorflow/tensor2tensor"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: What neural architecture overcomes the sequential computing limitations of most current model architectures for language and image modeling\n",
       "            <b><font color=#FA8072>Answer</font></b>: Transformer: a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: How quickly do the Transformer reach a new state-of-the art in translation quality?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: What features of this model are the same as RNN encoder-decoder architectures?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Transformer is the first transduction model relying entirely on attention to compute representations of its input and output without using sequence- aligned RNNs or convolution."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: What constraints in the model preclude parallelization?\n",
       "            <b><font color=#FA8072>Answer</font></b>: This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>11</b>. <b><font color=#FF7F50>Question</font></b>: What do current efforts focus on?\n",
       "            <b><font color=#FA8072>Answer</font></b>: recurrent models typically factor computation along the symbol positions of the input and output sequences"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>12</b>. <b><font color=#FF7F50>Question</font></b>: In what sequence transduction model is auto-regressive auto-attention used?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Transformer"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(txt5, NQUESTIONS, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe022d9b-7c72-4e72-b47b-35346eac069f",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Delete the SageMaker model and endpointDelete the SageMaker model and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd21b3e6-5055-41f5-9b8c-9faaeea66282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predictor.delete_model()\n",
    "model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09014e18-33e5-4185-ab90-9957c25d1f39",
   "metadata": {
    "tags": []
   },
   "source": [
    "To completely shutdown SageMaker, go to File > Shut Down > Shutdown All"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
